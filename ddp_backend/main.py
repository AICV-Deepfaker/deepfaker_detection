from pydantic import BaseModel
from typing import Literal
from contextlib import asynccontextmanager
import os
import shutil
import sys
from pathlib import Path
from typing import Annotated, Any

import torch
import uvicorn
from fastapi import FastAPI, File, Form, UploadFile
from pyngrok import ngrok

# from core.database import engine
# from models.models import Base

from detectors.wavelet_detector import WaveletDetector
from detectors.unite_detector import UniteDetector
from detectors.base_detector import BaseVideoConfig, BaseDetector, Scorable
from detectors.stt_detector import STTDetector

# ==========================================
# .env ë¡œë“œ
# ==========================================
from dotenv import load_dotenv

_BACKEND_DIR = Path(__file__).parent
load_dotenv(_BACKEND_DIR / ".env")

# ==========================================
# STT íŒŒì´í”„ë¼ì¸ ì„¤ì •
# ==========================================
_STT_DIR = Path(__file__).parent.parent / "STT"
sys.path.insert(0, str(_STT_DIR))

# STT .envë„ ì¶”ê°€ ë¡œë“œ (GROQ_API_KEY, TAVILY_API_KEYê°€ backend .envì— ì—†ì„ ê²½ìš° ëŒ€ë¹„)
load_dotenv(_STT_DIR / ".env")

_VIDEO_EXTENSIONS = {".mp4", ".avi", ".mov", ".mkv", ".wmv", ".flv", ".webm", ".m4v"}


def _is_video(filename: str) -> bool:
    return Path(filename).suffix.lower() in _VIDEO_EXTENSIONS


# ì„œë²„ê°€ ì‹œì‘ë  ë•Œ í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„± (JPAì˜ ddl-auto ê°™ì€ ì—­í• )
# Base.metadata.create_all(bind=engine)

# ëª¨ë¸ ë° í™˜ê²½ ë³€ìˆ˜
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
DETECTOR_YAML = "Wavelet-CLIP/wavelet_lib/config/detector/detector.yaml"
CKPT_PATH = "ddp_backend/ckpt_best.pth"
IMG_SIZE = 224

NGROK_AUTH_TOKEN = os.environ.get("NGROK_AUTH_TOKEN", "")

# UniteDetector (ì •ë°€íƒì§€ëª¨ë“œ / deep)
unite_detector = UniteDetector(
    BaseVideoConfig(
        model_path="./unite_baseline.onnx",
        img_size=384,
    )
)

# WaveletDetector (ì¦ê±°ìˆ˜ì§‘ëª¨ë“œ / fast)
wavelet_detector = WaveletDetector.from_yaml(DETECTOR_YAML, IMG_SIZE, CKPT_PATH)

detectors: dict[str, BaseDetector[Any, BaseModel]] = {
    "UNITE": unite_detector,
    "wavelet": wavelet_detector,
    "STT": STTDetector(),
}


@asynccontextmanager
async def lifespan(app: FastAPI):  # pyright: ignore[reportUnusedParameter]
    for next_detector in detectors.values():
        next_detector.load_model()
    public_url = None

    if NGROK_AUTH_TOKEN:
        ngrok.set_auth_token(NGROK_AUTH_TOKEN)
        tunnel = ngrok.connect("8000")
        public_url = tunnel.public_url
        print(f"\nğŸš€ ì™¸ë¶€ ì ‘ì† ì£¼ì†Œ (ngrok): {public_url}/predict")
    else:
        print("\nâš ï¸ NGROK í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ì—ì„œë§Œ ì ‘ì† ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    print("ğŸš€ FastAPI ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (Port: 8000)...")

    yield

    # [Shutdown] ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰
    if public_url:
        print("\nğŸ› ï¸ ngrok í„°ë„ì„ ì¢…ë£Œ ì¤‘ì…ë‹ˆë‹¤...")
        ngrok.disconnect(public_url)
        ngrok.kill()
        print("âœ… ngrokì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


app = FastAPI(lifespan=lifespan)


# ==========================================
# API ê²½ë¡œ
# ==========================================
@app.post("/predict/{mode}")
async def predict_deepfake(
    file: Annotated[UploadFile, File(...)], mode: Literal["deep", "fast"] = "fast"
):
    temp_path = f"temp_{file.filename}"
    model_names: dict[str, list[str]] = {"deep": ["UNITE"], "fast": ["wavelet", "STT"]}
    probs: list[float] = []
    try:
        total_response: dict[str, str | float | dict] = {}
        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        for next_model in model_names[mode]:
            model = detectors[next_model]

            report = await model.analyze(temp_path)
            response = report.model_dump()
            if isinstance(report, Scorable):
                probs.append(report.prob)
            response["status"] = "success"
            response["model_name"] = next_model
            total_response[next_model] = response
        
        avg_prob = sum(probs) / len(probs)
        confidence = (
            avg_prob if avg_prob > 0.5 else 1 - avg_prob
        )
        total_response["status"] = "success"
        total_response["result"] = "FAKE" if avg_prob > 0.5 else "REAL"
        total_response["avg_fake_prob"] = round(avg_prob, 4)
        total_response["confidence_score"] = f"{round(confidence * 100, 2)}%"
        total_response["analysis_mode"] = mode

        return total_response
    except Exception as e:
        return {"status": "error", "message": str(e)}
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


# ==========================================
# 6. ë©”ì¸ ì‹¤í–‰ë¶€
# ==========================================
if __name__ == "__main__":
    # ì¼ë°˜ .py íŒŒì¼ì—ì„œëŠ” nest_asyncioì™€ uvicorn.run ì¡°í•©ë³´ë‹¤
    # uvicorn.run(app) ì§ì ‘ í˜¸ì¶œì´ ë” ì•ˆì •ì ì…ë‹ˆë‹¤.
    uvicorn.run(app, host="0.0.0.0", port=8000)
