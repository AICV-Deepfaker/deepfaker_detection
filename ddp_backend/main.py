import os
import shutil
import sys
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Annotated, Any

import torch
import uvicorn
from detectors.base_detector import BaseDetector, BaseVideoConfig
from detectors.stt_detector import STTDetector
from detectors.unite_detector import UniteDetector

# from core.database import engine
# from models.models import Base
from detectors.wavelet_detector import WaveletDetector
from detectors import RPPGDetector

# ==========================================
# .env ë¡œë“œ
# ==========================================
from dotenv import load_dotenv
from fastapi import FastAPI, File, Form, UploadFile
from pyngrok import ngrok
from schemas import APIOutputFast, APIOutputDeep, BaseReport

_BACKEND_DIR = Path(__file__).parent
load_dotenv(_BACKEND_DIR / ".env")

# ==========================================
# STT íŒŒì´í”„ë¼ì¸ ì„¤ì •
# ==========================================
_STT_DIR = Path(__file__).parent.parent / "STT"
sys.path.insert(0, str(_STT_DIR))

# STT .envë„ ì¶”ê°€ ë¡œë“œ (GROQ_API_KEY, TAVILY_API_KEYê°€ backend .envì— ì—†ì„ ê²½ìš° ëŒ€ë¹„)
load_dotenv(_STT_DIR / ".env")

_VIDEO_EXTENSIONS = {".mp4", ".avi", ".mov", ".mkv", ".wmv", ".flv", ".webm", ".m4v"}


def _is_video(filename: str) -> bool:
    return Path(filename).suffix.lower() in _VIDEO_EXTENSIONS


# ì„œë²„ê°€ ì‹œì‘ë  ë•Œ í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„± (JPAì˜ ddl-auto ê°™ì€ ì—­í• )
# Base.metadata.create_all(bind=engine)

# ëª¨ë¸ ë° í™˜ê²½ ë³€ìˆ˜
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
DETECTOR_YAML = "Wavelet-CLIP/wavelet_lib/config/detector/detector.yaml"
CKPT_PATH = "ddp_backend/ckpt_best.pth"
IMG_SIZE = 224

NGROK_AUTH_TOKEN = os.environ.get("NGROK_AUTH_TOKEN", "")

# UniteDetector (ì •ë°€íƒì§€ëª¨ë“œ / deep)
unite_detector = UniteDetector(
    BaseVideoConfig(
        model_path="./unite_baseline.onnx",
        img_size=384,
    )
)

# WaveletDetector (ì¦ê±°ìˆ˜ì§‘ëª¨ë“œ / fast)
wavelet_detector = WaveletDetector.from_yaml(DETECTOR_YAML, IMG_SIZE, CKPT_PATH)

r_ppg_detector = RPPGDetector(BaseVideoConfig(model_path="", img_size=0))

stt_detector = STTDetector()

vid_detectors: dict[str, BaseDetector[Any, BaseReport]] = {
    "UNITE": unite_detector,
    "wavelet": wavelet_detector,
    "r_ppg": r_ppg_detector,
}


@asynccontextmanager
async def lifespan(app: FastAPI):  # pyright: ignore[reportUnusedParameter]
    for next_detector in vid_detectors.values():
        next_detector.load_model()
    public_url = None

    if NGROK_AUTH_TOKEN:
        ngrok.set_auth_token(NGROK_AUTH_TOKEN)
        tunnel = ngrok.connect("8000")
        public_url = tunnel.public_url
        print(f"\nğŸš€ ì™¸ë¶€ ì ‘ì† ì£¼ì†Œ (ngrok): {public_url}/predict")
    else:
        print("\nâš ï¸ NGROK í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ì—ì„œë§Œ ì ‘ì† ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    print("ğŸš€ FastAPI ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (Port: 8000)...")

    yield

    # [Shutdown] ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰
    if public_url:
        print("\nğŸ› ï¸ ngrok í„°ë„ì„ ì¢…ë£Œ ì¤‘ì…ë‹ˆë‹¤...")
        ngrok.disconnect(public_url)
        ngrok.kill()
        print("âœ… ngrokì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


app = FastAPI(lifespan=lifespan)


# ==========================================
# API ê²½ë¡œ
# ==========================================
@app.post("/predict/fast")
async def predict_deepfake_fast(
    file: Annotated[UploadFile, File(...)],
) -> APIOutputFast:
    temp_path = f"temp_{file.filename}"
    probs: float = 0

    try:
        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        wavelet_report = await wavelet_detector.analyze(temp_path)
        probs += wavelet_report.probability
        r_ppg_report = await r_ppg_detector.analyze(temp_path)
        probs += r_ppg_report.probability

        avg_prob = probs / 2

        stt_report = await stt_detector.analyze(temp_path)
        
        confidence = avg_prob if avg_prob > 0.5 else 1 - avg_prob
        return APIOutputFast(
            status="success",
            result="FAKE" if avg_prob > 0.5 else "REAL",
            average_fake_prob=round(avg_prob, 4),
            confidence_score=f"{round(confidence * 100, 2)}%",
            analysis_mode="fast",
            wavelet=wavelet_report,
            r_ppg=r_ppg_report,
            stt=stt_report
        )
    except Exception as e:
        return APIOutputFast(
            status='error',
            error_msg=str(e),
            result='FAKE',
            average_fake_prob=0,
            confidence_score="",
            analysis_mode="fast",
        )
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

@app.post("/predict/deep")
async def predict_deepfake_deep(
    file: Annotated[UploadFile, File(...)],
) -> APIOutputDeep:
    temp_path = f"temp_{file.filename}"

    try:
        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        unite_report = await unite_detector.analyze(temp_path)

        return APIOutputDeep(
            status="success",
            result=unite_report.result,
            average_fake_prob=unite_report.probability,
            confidence_score=unite_report.confidence_score,
            analysis_mode="deep",
            unite=unite_report,
        )
    except Exception as e:
        return APIOutputDeep(
            status='error',
            error_msg=str(e),
            result='FAKE',
            average_fake_prob=0,
            confidence_score="",
            analysis_mode="fast",
        )
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


# ==========================================
# 6. ë©”ì¸ ì‹¤í–‰ë¶€
# ==========================================
if __name__ == "__main__":
    # ì¼ë°˜ .py íŒŒì¼ì—ì„œëŠ” nest_asyncioì™€ uvicorn.run ì¡°í•©ë³´ë‹¤
    # uvicorn.run(app) ì§ì ‘ í˜¸ì¶œì´ ë” ì•ˆì •ì ì…ë‹ˆë‹¤.
    uvicorn.run(app, host="0.0.0.0", port=8000)
